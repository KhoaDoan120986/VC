{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529f77e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 1.13.0+cu116\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from open_clip import create_model_from_pretrained, get_tokenizer\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa1f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/MSVD/features/MSVD_annotations.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "res = {}\n",
    "for key in data.keys():\n",
    "    seen = set()\n",
    "    res[key] = {}\n",
    "    res[key]['entities']  = data[key]['class']\n",
    "    res[key]['relations'] = []\n",
    "    for h, r, t in data[key]['sorted_triplets']:\n",
    "        if r not in seen:\n",
    "            seen.add(r)\n",
    "            res[key]['relations'].append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6737c1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, preprocess = create_model_from_pretrained('hf-hub:apple/DFN2B-CLIP-ViT-B-16') #xclip\n",
    "tokenizer = get_tokenizer('ViT-B-16')\n",
    "\n",
    "model.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca7809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "with open(\"../Dataset/MSVD/captions/youtube-mapping.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        part = line.split(\" \")\n",
    "        mapping[part[1].strip(\"\\n\")] = part[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "910a8348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1970/1970 [04:26<00:00,  7.39it/s]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"data/MSVD/features/MSVD_semantic_clip.hdf5\", \"w\") as fs:\n",
    "    for key in tqdm(res.keys()):\n",
    "        video_id = mapping[key]\n",
    "        with torch.no_grad():\n",
    "            ent_tokens = tokenizer(res[key]['entities'])\n",
    "            ent_embedding = model.encode_text(ent_tokens.cuda())\n",
    "            ent_embedding = ent_embedding / ent_embedding.norm(dim=-1, keepdim=True)\n",
    "            ent_embedding = ent_embedding.cpu()\n",
    "\n",
    "            rel_tokens = tokenizer(res[key]['relations'])\n",
    "            rel_embedding = model.encode_text(rel_tokens.cuda())\n",
    "            rel_embedding = rel_embedding / rel_embedding.norm(dim=-1, keepdim=True)\n",
    "            rel_embedding = rel_embedding.cpu()\n",
    "\n",
    "            embeddings= torch.cat([ent_embedding, rel_embedding])\n",
    "            fs.create_dataset(video_id, data=embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
